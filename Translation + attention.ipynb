{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FzDcfnOvPYnR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "\n",
    "from utils2 import translate_sentence, save_checkpoint, load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xMOTOdRgHlAl",
    "outputId": "d9edc366-d533-4859-e2b8-88b2a4090258"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "BkhAPN502QtF",
    "outputId": "aa86a622-f122-4570-94e3-65c04871c452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "✔ Download and installation successful\n",
      "You can now load the model via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "import en_core_web_sm\n",
    "import de_core_news_sm\n",
    "\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "spacy.cli.download(\"de_core_news_sm\")\n",
    "\n",
    "\n",
    "spacy_ger = de_core_news_sm.load()\n",
    "spacy_eng = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xiGiEV4280s"
   },
   "outputs": [],
   "source": [
    "def tokenizer_de(text):\n",
    "  return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
    "\n",
    "def tokenizer_eng(text):\n",
    "  return [tok.text for tok in spacy_eng.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cvgTWYkg46Zz",
    "outputId": "f6c81dc4-c3e3-418f-b14d-10a1810a8a2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'ate', 'my', 'friends', \"'s\", \"O'neal\", 'apple', 'yesterday']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_eng(\"I ate my friends's O'neal apple yesterday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-IYtkU05ACP"
   },
   "outputs": [],
   "source": [
    "german = Field(tokenize=tokenizer_de, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "english = Field(\n",
    "    tokenize=tokenizer_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tG2khqwP5RkZ"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts=(\".de\", \".en\"), fields=(german, english)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZofP4s77Zkl"
   },
   "outputs": [],
   "source": [
    "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five most common words in the dataset: [('a', 49165), ('.', 27623), ('in', 14886), ('the', 10955), ('on', 8035)]\n"
     ]
    }
   ],
   "source": [
    "#vocab.freqs in a python counter datatype\n",
    "print(\"Five most common words in the dataset: \" + str(english.vocab.freqs.most_common(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RRksTdJk86iE"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True)\n",
    "\n",
    "        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        encoder_states, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size*2)\n",
    "\n",
    "        # Use forward, backward cells and hidden through a linear layer\n",
    "        # so that it can be input to the decoder which is not bidirectional\n",
    "        # Also using index slicing ([idx:idx+1]) to keep the dimension\n",
    "        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "        \n",
    "        return encoder_states, hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QrDzJNnC9BcE"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(hidden_size * 2 + embedding_size, hidden_size, num_layers)\n",
    "\n",
    "        self.energy = nn.Linear(hidden_size * 3, 1)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "        # x: (1, N) where N is the batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        # encoder_states: (seq_length, N, hidden_size*2)\n",
    "        sequence_length = encoder_states.shape[0]\n",
    "        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
    "        # h_reshaped: (seq_length, N, hidden_size)\n",
    "\n",
    "        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
    "        # energy: (seq_length, N, 1)\n",
    "\n",
    "        attention = self.softmax(energy)\n",
    "        # attention: (seq_length, N, 1)\n",
    "\n",
    "        # attention: (seq_length, N, 1), snk\n",
    "        # encoder_states: (seq_length, N, hidden_size*2), snl\n",
    "        # we want context_vector: (1, N, hidden_size*2), i.e knl\n",
    "        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_states)\n",
    "\n",
    "        rnn_input = torch.cat((context_vector, embedding), dim=2)\n",
    "        # rnn_input: (1, N, hidden_size*2 + embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs).squeeze(0)\n",
    "        # predictions: (N, hidden_size)\n",
    "\n",
    "        return predictions, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9OYoA3waBGZF"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(english.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "        encoder_states, hidden, cell = self.encoder(source)\n",
    "\n",
    "        # First input will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # At every time step use encoder_states and update hidden, cell\n",
    "            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
    "\n",
    "            # Store prediction for current time step\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J46bfkFBCoOn"
   },
   "outputs": [],
   "source": [
    "#Training Hyperparameters\n",
    "num_epochs = 100\n",
    "lr = 3e-4\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sUzYsQulCp0X"
   },
   "outputs": [],
   "source": [
    "#Model Hyperparameter\n",
    "load_model = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size_encoder = len(german.vocab)\n",
    "input_size_decoder = len(english.vocab)\n",
    "output_size = len(english.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 1\n",
    "enc_dropout = 0.0\n",
    "dec_dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLW4Bs-KE-dW"
   },
   "outputs": [],
   "source": [
    "step = 0\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2],\n",
       "        [   4,    4,    4,    4,    4,    4,    4,    4,    4,  402,  388,    4,\n",
       "           16,    4,    4,   16,    4,    4,    4,   16,    4,    4,    4,    9,\n",
       "         3123,    4,    9,    7,   30,    4,    4,    4],\n",
       "        [  14,    9,    9,   24,  348,    9,   38,   14,    9, 1071,   30,   38,\n",
       "         3724,  122,   14,   50,   24, 2555,   14,   30,    9,    9,   38,    6,\n",
       "         1827,  682,    6,   33,    6,    9,   87,   33],\n",
       "        [  11,   10,  636,   33,   10,  137,   12,    6,    6,    0,    6,   12,\n",
       "            6,   14,   36,   32,   14,  831,   56,   73,   45,   37,   12,  231,\n",
       "           20,    9,  132,   10,   86,   32,   10,  189],\n",
       "        [  55,   92,   73,   13,   92,   13,  127,    4,    4,    4,  890,   19,\n",
       "         3664,   20,    6,    8,    6,  301,   20,   51,    4,    4,  196, 1250,\n",
       "            4,   22,   23,   32,  468,    8,   56,   10],\n",
       "        [ 681,   13,    6,  122,    8,    4,    6,   25,   26, 1237,  219,   17,\n",
       "           29,    7,   43,    4,    4,    4,   44,  613, 4534, 2236,   41,  121,\n",
       "          715,  146,  841,   20,   11,    7,   20,  334],\n",
       "        [  18,    7,   27,   42,    4,  153,   52,   23,  208,   12, 2822,   36,\n",
       "          541,   88,   12,  425,   25,   14,  286,    4, 4462,  689,   40,   13,\n",
       "          684,   11,    4,    7,   25,  259,    4,   49],\n",
       "        [1139,   68,  545,   97,  520,   15,   11,   10,   42,    4,   66,   83,\n",
       "          623,   92,    4,   13,   23,  189,   28,  289,    6,   28,    4,    4,\n",
       "          159,    4,   99,  657,  325,   71, 5611,   72],\n",
       "        [ 557,    6,   58,   11,  222,   45,   29, 1137,   23,    9,  181, 1880,\n",
       "         3094,   83,   77,   31,   11,   10,    4,  358,   43,   56, 5476,   38,\n",
       "            8,   26,  236,  412,  279,   18,   28,   19],\n",
       "        [   4,  139,  205,  146,   13,  143,  693,   65,   10,   32,   69,  421,\n",
       "            8,   58,   58,   11,   29,  334,    9,    5,   12,   51,   45,   12,\n",
       "            7,   23,    4,    7,  100,    4,   45,   10],\n",
       "        [ 157,  226,  107,   32, 3200,   51,  308,   93,   92,   11,    7,  871,\n",
       "            7,  313,  285,   25,  640,   49,  229,    3,   21,   20,  711,   63,\n",
       "           84, 4115,  159,  565,    8, 1407,   66,  165],\n",
       "        [   5,    4,   20,   20, 1564,   69,   52,    6,  121,   22,  103,    4,\n",
       "          390,   10,  607, 1808,   10,    4,   44,    1,  310,    7,    5,    5,\n",
       "            5,   21,    5,   12, 5551,   21,  181,    4],\n",
       "        [   3, 1438,   27,    4,    5,    7,   11,    4,    8,   26,    5, 1933,\n",
       "          222,  304,  246,   13,   37, 2499,    5,    1,   52, 1313,    3,    3,\n",
       "            3,  487,    3,  367,  130,  565,    6,  134],\n",
       "        [   1,   51,  776,   94,    3,  103,   29, 3334,   27,    5,    3,  105,\n",
       "         1059,   44,   66, 3913,    4,   12,    3,    1,  564,    5,    1,    1,\n",
       "            1,    5,    1,   11,    5,    5,    7,   20],\n",
       "        [   1,  224,    5,    6,    1,    5,  543,    5,   86,    3,    1,   11,\n",
       "            5, 1398,  184,  344, 1351, 1514,    1,    1,   13,    3,    1,    1,\n",
       "            1,    3,    1,    7,    3,    3,  103,    4],\n",
       "        [   1,  135,    3,    4,    1,    3,    6,    3,   99,    1,    1,    4,\n",
       "            3,   11,    5,  155,    5,    5,    1,    1, 3354,    1,    1,    1,\n",
       "            1,    1,    1, 1361,    1,    1,    3,  505],\n",
       "        [   1,    5,    1,  235,    1,    1,    7,    1,    5,    1,    1, 3201,\n",
       "            1,    0,    3,  405,    3,    3,    1,    1,    6,    1,    1,    1,\n",
       "            1,    1,    1,  925,    1,    1,    1,    5],\n",
       "        [   1,    3,    1,    5,    1,    1,  103,    1,    3,    1,    1,  382,\n",
       "            1,    5,    1,    5,    1,    1,    1,    1,  141,    1,    1,    1,\n",
       "            1,    1,    1,    5,    1,    1,    1,    3],\n",
       "        [   1,    1,    1,    3,    1,    1,   18,    1,    1,    1,    1,    5,\n",
       "            1,    3,    1,    3,    1,    1,    1,    1,    5,    1,    1,    1,\n",
       "            1,    1,    1,    3,    1,    1,    1,    1],\n",
       "        [   1,    1,    1,    1,    1,    1,   21,    1,    1,    1,    1,    3,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    3,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   1,    1,    1,    1,    1,    1,    8,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   1,    1,    1,    1,    1,    1,   42,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   1,    1,    1,    1,    1,    1,   56,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   1,    1,    1,    1,    1,    1,   87,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   1,    1,    1,    1,    1,    1,    5,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1],\n",
       "        [   1,    1,    1,    1,    1,    1,    3,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iterator)).trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Md1-WY2sFk_5"
   },
   "outputs": [],
   "source": [
    "encoder_net = Encoder(input_size_encoder, encoder_embedding_size, \n",
    "                      hidden_size, num_layers, enc_dropout).to(device)\n",
    "\n",
    "decoder_net = Decoder(input_size_decoder, decoder_embedding_size, \n",
    "                      hidden_size, output_size, num_layers, dec_dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsrP9RA3GQhe"
   },
   "outputs": [],
   "source": [
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkuWFA8lGXZe"
   },
   "outputs": [],
   "source": [
    "pad_idx = english.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JESCqAA7GlBG"
   },
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load('my_checkpoint.pth.ptar'), model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "dN3cxS5oMnsk",
    "outputId": "629bf5b2-d54e-4495-caba-0a0b48a0829b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0 / 100]\n",
      "=> Saving checkpoint\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Hreshapedtorch.Size([17, 1, 1024])\n",
      "torch.Size([17, 1, 2048])\n",
      "Translated example sentence: \n",
      " ['routine', 'press', 'rollerskating', 'interviews', 'points', 'mounted', 'bunch', 'know', 'sacks', 'styrofoam', 'lush', 'mount', 'zebra', 'year', 'wakeboard', '7', 'tractor', 'gingerbread', 'accompanied', 'drawing', 'excited', 'spattered', 'highway', 'iced', 'having', 'involved', 'neighbors', 'alley', 'flowered', 'aboard', 'doctors', 'leak', 'model', 'riding', 'plywood', 'kick', 'carnival', 'seven', 'flood', 'a', 'intrigued', 'utility', 'eyeliner', 'his', 'fixes', 'sunbathers', 'large', 'rimmed', 'villagers', 'burgers']\n",
      "Source sentence len 14\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Hreshapedtorch.Size([14, 32, 1024])\n",
      "torch.Size([14, 32, 2048])\n",
      "Source sentence len 19\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Hreshapedtorch.Size([19, 32, 1024])\n",
      "torch.Size([19, 32, 2048])\n",
      "Source sentence len 13\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n",
      "Hreshapedtorch.Size([13, 32, 1024])\n",
      "torch.Size([13, 32, 2048])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-f0bccdf253c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mtotal_norm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    print(f'Epoch [{epoch} / {num_epochs}]')\n",
    "\n",
    "    checkpoint = {'state_dict': model.state_dict(), optimizer: optimizer.state_dict()}\n",
    "    save_checkpoint(checkpoint)\n",
    "\n",
    "    model.eval()\n",
    "    translated_sentence = translate_sentence(model, sentence, german, english, device, max_length=50)\n",
    "\n",
    "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        \n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "\n",
    "        output = model(inp_data, target)\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "\n",
    "        step = step + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CyrheTh3OibP"
   },
   "outputs": [],
   "source": [
    "translate_sentence(model, \"Diese Jungs schauen sich jeden Tag die Nachrichten an\", german, english, device, max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Translation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
