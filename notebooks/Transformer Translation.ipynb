{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FzDcfnOvPYnR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\"IN_LANG\":\"en\", \"OUT_LANG\": \"de\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "BkhAPN502QtF",
    "outputId": "aa86a622-f122-4570-94e3-65c04871c452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "✔ Download and installation successful\n",
      "You can now load the model via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "import en_core_web_sm\n",
    "import de_core_news_sm\n",
    "\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "spacy.cli.download(\"de_core_news_sm\")\n",
    "\n",
    "\n",
    "if CFG[\"IN_LANG\"] == \"en\":\n",
    "    spacy_in_lang = en_core_web_sm.load()\n",
    "    spacy_out_lang = de_core_news_sm.load()\n",
    "else:\n",
    "    spacy_in_lang = de_core_news_sm.load()\n",
    "    spacy_out_lang = en_core_web_sm.load()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xiGiEV4280s"
   },
   "outputs": [],
   "source": [
    "def tokenizer_in(text):\n",
    "    return [tok.text for tok in spacy_in_lang.tokenizer(text)]\n",
    "\n",
    "def tokenizer_out(text):\n",
    "    return [tok.text for tok in spacy_out_lang.tokenizer(text)]\n",
    "\n",
    "in_lang = Field(tokenize=tokenizer_in, lower=True)\n",
    "out_lang = Field(tokenize=tokenizer_out, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-IYtkU05ACP"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "        exts=(\".\"+CFG[\"IN_LANG\"], \".\"+CFG[\"OUT_LANG\"]), fields=(in_lang, out_lang ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_lang.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "out_lang.build_vocab(train_data, max_size=10000, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module): #Positional encoding from: https://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.scale = nn.Parameter(torch.ones(1))\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(\n",
    "            0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.scale * self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, intoken, outtoken ,hidden, enc_layers=2, dec_layers=2, dropout=.1, nheads=2, ff_model=128):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Embedding(intoken, hidden)\n",
    "        self.pos_encoder = PositionalEncoding(hidden, dropout)\n",
    "\n",
    "        self.decoder = nn.Embedding(outtoken, hidden) \n",
    "        self.pos_decoder = PositionalEncoding(hidden, dropout)\n",
    "        \n",
    "        \n",
    "        encoder_layers = TransformerEncoderLayer(d_model=hidden, nhead = nheads, dim_feedforward = ff_model, dropout=dropout, activation='relu')\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, enc_layers)\n",
    "\n",
    "        encoder_layers = TransformerDecoderLayer(hidden, nheads, ff_model, dropout, activation='relu')\n",
    "        self.transformer_decoder = TransformerDecoder(encoder_layers, dec_layers)        \n",
    "\n",
    "        self.fc_out = nn.Linear(hidden, outtoken)\n",
    "\n",
    "        self.src_mask = None\n",
    "        self.trg_mask = None\n",
    "        self.memory_mask = None\n",
    "\n",
    "        \n",
    "    def generate_square_subsequent_mask(self, sz, sz1=None):\n",
    "        \n",
    "        if sz1 == None:\n",
    "            mask = torch.triu(torch.ones(sz, sz), 1)\n",
    "        else:\n",
    "            mask = torch.triu(torch.ones(sz, sz1), 1)\n",
    "            \n",
    "        return mask.masked_fill(mask==1, float('-inf'))\n",
    "\n",
    "    def make_len_mask_enc(self, inp):\n",
    "        return (inp == in_pad_idx).transpose(0, 1)   #(batch_size, output_seq_len)\n",
    "    \n",
    "    def make_len_mask_dec(self, inp):\n",
    "        return (inp == out_pad_idx).transpose(0, 1) #(batch_size, input_seq_len)\n",
    "    \n",
    "\n",
    "\n",
    "    def forward(self, src, trg): #SRC: (seq_len, batch_size)\n",
    "\n",
    "        if self.trg_mask is None or self.trg_mask.size(0) != len(trg):\n",
    "            self.trg_mask = self.generate_square_subsequent_mask(len(trg)).to(trg.device)\n",
    "            \n",
    "\n",
    "        #Adding padding mask\n",
    "        src_pad_mask = self.make_len_mask_enc(src)\n",
    "        trg_pad_mask = self.make_len_mask_dec(trg)\n",
    "             \n",
    "\n",
    "        #Add embeddings Encoder\n",
    "        src = self.encoder(src)  #Embedding, (seq_len, batch_size, d_model)\n",
    "        src = self.pos_encoder(src)   #Pos embedding\n",
    "        \n",
    "        \n",
    "        #Add embedding decoder\n",
    "        trg = self.decoder(trg) #(seq_len, batch_size, d_model)\n",
    "        trg = self.pos_decoder(trg)\n",
    "\n",
    "        \n",
    "        memory = self.transformer_encoder(src, None, src_pad_mask)\n",
    "        output = self.transformer_decoder(tgt = trg, memory = memory, tgt_mask = self.trg_mask, memory_mask = None, \n",
    "                                          tgt_key_padding_mask = trg_pad_mask, memory_key_padding_mask = src_pad_mask)\n",
    "\n",
    "        output = self.fc_out(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Hyperparameters\n",
    "num_epochs = 60\n",
    "batch_size = 128\n",
    "\n",
    "maxlen = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Hyperparameter\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size_encoder = len(in_lang.vocab)\n",
    "input_size_decoder = len(out_lang.vocab)\n",
    "output_size = len(out_lang.vocab)\n",
    "\n",
    "d_model = 256\n",
    "\n",
    "import math \n",
    "\n",
    "model = TransformerModel(input_size_encoder, input_size_decoder ,d_model, enc_layers=1, dec_layers=1, dropout=.1, nheads=1, ff_model=1028).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_pad_idx = in_lang.vocab.stoi['<pad>']\n",
    "out_pad_idx = out_lang.vocab.stoi['<pad>']\n",
    "\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=out_pad_idx)\n",
    "optimizer = NoamOpt(d_model, 1, 4000 ,optim.Adam(model.parameters(), lr=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence_transformer(model, sentence, max_length=50):\n",
    "    model.eval()\n",
    "    tokens = [token.text.lower() for token in spacy_in_lang(sentence)]\n",
    "\n",
    "    text_to_indices = [in_lang.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    preds = [out_lang.vocab.stoi[out_lang.init_token]]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        emb_src = model.encoder(sentence_tensor)\n",
    "        emb_src = model.pos_encoder(emb_src)\n",
    "\n",
    "        memory = model.transformer_encoder(emb_src)\n",
    "\n",
    "        for i in range(50):\n",
    "\n",
    "            trg = torch.Tensor(preds).long().unsqueeze(1).to(device)\n",
    "            trg = model.decoder(trg)\n",
    "            trg = model.pos_decoder(trg)\n",
    "\n",
    "            out = model.transformer_decoder(tgt = trg, memory = memory)\n",
    "            out = model.fc_out(out)\n",
    "            \n",
    "            \n",
    "\n",
    "            new = out.squeeze(1)[-1].argmax().item()\n",
    "            preds.append(new)\n",
    "            if new == out_lang.vocab.stoi[\"<eos>\"]:\n",
    "                break\n",
    "\n",
    "    \n",
    "    return [out_lang.vocab.itos[i] for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_out_encoder(src):\n",
    "    \n",
    "    model.eval()\n",
    "    tokens = [token.text.lower() for token in spacy_in_lang(src)]\n",
    "\n",
    "    text_to_indices = [in_lang.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        emb_src = model.encoder(sentence_tensor)\n",
    "        emb_src = model.pos_encoder(emb_src)\n",
    "\n",
    "        memory = model.transformer_encoder(emb_src)\n",
    "\n",
    "        return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam(phrase, k):\n",
    "    \n",
    "    model.eval()\n",
    "    memory = get_out_encoder(phrase)\n",
    "\n",
    "    sos = out_lang.vocab.stoi[\"<sos>\"]\n",
    "    tgt = [sos]\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        trg = torch.Tensor(tgt).long().unsqueeze(1).to(device)\n",
    "        trg = model.decoder(trg)\n",
    "        trg = model.pos_decoder(trg)\n",
    "\n",
    "        out = model.transformer_decoder(tgt = trg, memory = memory)\n",
    "        out = F.softmax(model.fc_out(out), dim=-1)[-1].squeeze()\n",
    "\n",
    "        args = out.argsort()[-k:].detach().cpu().numpy()\n",
    "        probs = out[args].detach().cpu().numpy()\n",
    "\n",
    "        probs = np.log(probs)\n",
    "        possible = list(zip([tgt + [args[i]] for i in range(k)], probs))\n",
    "        \n",
    "        for i in range(maxlen):\n",
    "\n",
    "            test=  []\n",
    "            for j in range(k):\n",
    "\n",
    "                tmp_tgt, tmp_prob = possible[j]\n",
    "\n",
    "                if tmp_tgt[-1] == out_lang.vocab.stoi[\"<eos>\"]:\n",
    "                    test.append(possible[j])\n",
    "\n",
    "                else:\n",
    "                    trg = torch.Tensor(tmp_tgt).long().unsqueeze(1).to(device)\n",
    "                    trg = model.decoder(trg)\n",
    "                    trg = model.pos_decoder(trg)\n",
    "\n",
    "                    out = model.transformer_decoder(tgt = trg, memory = memory)\n",
    "                    out = F.softmax(model.fc_out(out), dim=-1)[-1].squeeze()\n",
    "\n",
    "                    tmp_args = out.argsort()[-k:].detach().cpu().numpy()\n",
    "                    tmp_probs = out[tmp_args].detach().cpu().numpy()\n",
    "                    tmp_probs = (tmp_prob + np.log(tmp_probs))/(len(tmp_tgt)-1)\n",
    "\n",
    "                    for r in range(k): \n",
    "                        test.append((tmp_tgt + [tmp_args[r]], tmp_probs[r]))\n",
    "\n",
    "\n",
    "            possible = sorted(test, key=lambda x:x[1], reverse=True)[:k]\n",
    "            \n",
    "    return possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(x):\n",
    "    \n",
    "    sentence = x[0]\n",
    "    sentence = [out_lang.vocab.itos[i] for i in sentence]\n",
    "    \n",
    "    return (\" \".join(sentence), x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch():\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        \n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "\n",
    "        output = model(inp_data, target[:-1, ])\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "        total_loss += loss\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    return total_loss/len(train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validation():\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch_idx, batch in enumerate(valid_iterator):\n",
    "\n",
    "            inp_data = batch.src.to(device)\n",
    "            target = batch.trg.to(device)\n",
    "\n",
    "            output = model(inp_data, target[:-1, ])\n",
    "            output = output.reshape(-1, output.shape[2])\n",
    "            target = target[1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss\n",
    "\n",
    "\n",
    "    return total_loss/len(valid_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0 / 60]\n",
      "\n",
      "Translated example sentence: \n",
      " [('<sos> ein mann in einem grünen gitarre und ein mann und ein mann in der hand . <eos>', -0.002370434), ('<sos> ein mann in grünen oberteil hält eine gitarre , während ein mann in der hand . <eos>', -0.0024878283)]\n",
      "Greedy: ['<sos>', 'ein', 'mann', 'in', 'grünen', 'oberteil', 'hält', 'eine', 'gitarre', ',', 'während', 'ein', 'mann', 'in', 'der', 'hand', '.', '<eos>']\n",
      "\n",
      " Train loss 2.9315173625946045 | Validation loss 2.6100471019744873 \n",
      " \n",
      "\n",
      "Epoch [1 / 60]\n",
      "\n",
      "Translated example sentence: \n",
      " [('<sos> ein mann in einem grünen gitarre , während ein mann in der nähe eines mannes . <eos>', -0.00122195), ('<sos> ein mann im grünen oberteil hält einen anderen mann , während ein mann in der hand . <eos>', -0.001357117)]\n",
      "Greedy: ['<sos>', 'ein', 'mann', 'in', 'einem', 'grünen', 'gitarre', ',', 'während', 'andere', 'mann', 'in', 'der', 'nähe', 'eines', 'mannes', '.', '<eos>']\n",
      "\n",
      " Train loss 2.6698379516601562 | Validation loss 2.3837783336639404 \n",
      " \n",
      "\n",
      "Epoch [2 / 60]\n",
      "\n",
      "Translated example sentence: \n",
      " [('<sos> ein mann im grünen gitarre hält eine gitarre , während ein mann in der anderen mann . <eos>', -0.0020078328), ('<sos> ein mann in grünem grünem hemd und ein mann in der anderen mann . <eos>', -0.0048695686)]\n",
      "Greedy: ['<sos>', 'ein', 'mann', 'in', 'grünen', 'grünem', 'hemd', 'und', 'ein', 'mann', 'in', 'der', 'anderen', 'mann', '.', '<eos>']\n",
      "\n",
      " Train loss 2.452869176864624 | Validation loss 2.2253570556640625 \n",
      " \n",
      "\n",
      "Epoch [3 / 60]\n",
      "\n",
      "Translated example sentence: \n",
      " [('<sos> ein mann in grünem hemd hält eine gitarre , während ein mann in einem <unk> . <eos>', -0.0039127436), ('<sos> ein mann im grünen gitarre hält eine gitarre , während ein mann in einem <unk> . <eos>', -0.003928006)]\n",
      "Greedy: ['<sos>', 'ein', 'mann', 'in', 'grüner', 'hält', 'eine', 'gitarre', ',', 'während', 'ein', 'mann', 'in', 'der', 'anderen', 'mann', '.', '<eos>']\n",
      "\n",
      " Train loss 2.2562897205352783 | Validation loss 2.067538261413574 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = 'a man in green holds a guitar while the other man observes his shirt .'\n",
    "\n",
    "\n",
    "best_loss = 6486468 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    print(f'Epoch [{epoch} / {num_epochs}]\\n')\n",
    "    \n",
    "    loss = run_epoch()\n",
    "    validation_loss = run_validation()\n",
    "\n",
    "    translated_sentence = translate_sentence_transformer(model, sentence)\n",
    "    out = beam(sentence, 3)   \n",
    "    \n",
    "    print(f\"Translated example sentence: \\n {list(map(convert, out[:2]))}\")\n",
    "    print(f\"Greedy: {translated_sentence}\")\n",
    "    \n",
    "    print(f\"\\n Train loss {loss} | Validation loss {validation_loss} \\n \\n\")\n",
    "    \n",
    "    if validation_loss < best_loss:\n",
    "        torch.save(model.state_dict(), \"../models/new_transformer\")\n",
    "        best_loss = validation_loss\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Translation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
